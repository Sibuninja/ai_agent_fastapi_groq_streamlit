# ğŸ§  AI Agent Chatbot + PDF RAG

This project is an AI-powered assistant that supports both:
- ğŸ“š RAG (Retrieval-Augmented Generation) from uploaded PDFs
- ğŸ¤– Agent-based chat using Groq or OpenAI models

## ğŸš€ Features
- Upload a PDF and ask questions from it (RAG)
- Choose AI models like `LLaMA-3`, `Mixtral`, or `GPT-4o-mini`
- Supports web search toggle (if implemented in backend)
- Built with FastAPI + Streamlit

## ğŸ–¼ Interface Preview

![Agent Interface](assets/AgentDashboard.png)

![RAG Interface](assets/RagDashboard.png)


## ğŸ§© Project Structure
```
ğŸ“ ai_agent_fastapi_groq_streamlit
â”œâ”€â”€ backend.py         # FastAPI backend with /chat, /upload, /ask_rag
â”œâ”€â”€ frontend.py        # Streamlit frontend UI
â”œâ”€â”€ ai_agent.py        # Handles generic model-based responses
â”œâ”€â”€ rag_engine.py      # Embeds and searches PDF content
â”œâ”€â”€ utils_rag.py       # Query Groq with context prompt
â”œâ”€â”€ .env               # Contains GROQ_API_KEY and other secrets
â”œâ”€â”€ requirements.txt   # Python dependencies
```

## ğŸ“¦ Installation

1. Clone the repo and move into it:

```bash
git clone https://github.com/Sibuninja/ai_agent_fastapi_groq_streamlit.git
cd ai_agent_fastapi_groq_streamlit
```

2. Create virtual environment and activate:

```bash
python -m venv venv
venv\Scripts\activate
```

3. Install dependencies:

```bash
pip install -r requirements.txt
```

4. Create a `.env` file with your keys:

```
GROQ_API_KEY=your_groq_api_key_here
OPENAI_API_KEY=your_openai_key_here  # if used
```

## â–¶ï¸ Run

Start backend:
```bash
uvicorn backend:app --reload --port 9999
```

Start frontend:
```bash
streamlit run frontend.py
```

---

## ğŸ›¡ï¸ Notes
- Don't commit your `.env` or `venv/` folder.
- Avoid pushing large files like `.dll`, `.lib`, or model weights.